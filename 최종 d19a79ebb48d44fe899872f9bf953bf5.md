# 최종

![back.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/back.png)

# Team DI 주제

### “아니, 쏘카존에 반납하려니까 만석이라 다른 곳에 주차했더니 패널티라네요.”

[쏘카, 차량 반납존 만석으로 임의 주차시 페널티 부과된다?..."고객센터를 통해 주차할 수 있도록 안내하고 있다"](http://www.newsworker.co.kr/news/articleView.html?idxno=113012)

: 쏘카는 전통적인 차량 렌트 시장과 다르게, 기술을 이용하여 뛰어난 사용자 경험을 제공한다. 차량을 빌리고 반납하는 전 과정이 digital transformation 되었으며, 기존의 대체재보다 월등한 편리성을 제공한다. 

하지만 이용 경험 중 차량 반납 단계에서, 예상치 못하게 주차공간이 없을 때 불편함을 겪는 사용자들이 존재해왔다. 이를 사용자가 문제에 직면하기 전 선제적으로 반응하기 위해, object detection을 이용한 **반납 장소의 실시간 주차 가능 여부**를 파악할 수 있는 서비스를 만들고자 하였다. 

### → “우리가 주차장의 상황을 알려주면 되지 않을까?”

### 주차장 상황 및 주차 가능 여부 정보 제공

~~<teamdi.xyz>사진 1장~~

---

## 주차장에서 어떤 요소들이 중요할까?

### **실내 주차장 / 실외 주차장**이 중요할 것이다.

실내 주차장과 실외 주차장의 상황은 다르다. 실내 주차장의 경우 카메라 높이, 카메라의 각도 등의 제약이 있을 수 있고, 실외 주차장의 경우 날씨의 변수, 빛의 양과 각도 등이 주차 공간을 찾는데 중요한 변수가 될 수 있을 것이라 가정했다.

### 주차장의 종류와 관계없이 카메라 각도가 중요할 것이다.

비교적 단순한 차와 빈 공간을 구분하는데에는 카메라의 각도에 따라 차량이 어느 정도 보이는지, 카메라의 설정에 따라 얼마나 왜곡된 각도로 찍힌 사진인지, 이런 요소는 주차장과 상관없이 중요한 학습 요소로 작용할 것이라고 가정했다.

### 주차장 자체가 중요할 것이다.

주차장마다 주차 할 수 있는 공간의 각도, 주차선의 선명도와 굵기와 같은 개별 요소들이 있고 지형지물의 상태가 모두 다르기 때문에 각 장소의 특성이 중요할 것이라 가정했다.

---

## 실제 학습을 진행하면서 알아보자!

### 어떤 모델을 사용할까?

### [Yolo v5](https://github.com/ultralytics/yolov5)

: 현재 Object detection에서 뛰어난 성능을 보이고 있는 Yolo v5를 pretrained model로 활용하기로 했다. 그리고 각 중요하다고 생각하는 요소에 맞춰 detect하도록 fine tuning을 하자.

![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled.png)

### 어떤 데이터를 사용할까?

- 주차장의 이미지 데이터는 cctv 혹은 자동차의 블랙박스로 얻을 수 있을 것이라 판단했다.
- 하지만 쏘카 이용자가 주차장에 가기 전에 주차장에 관한 정보를 제공해주어야 하기 때문에, 블랙박스보다는 cctv 이미지가 더욱더 의미가 있을 것이라 판단했다.
- 문제는! 보안상 문제로 직접적으로 전달받을 수 있는 데이터셋이 없기 때문에, 스스로 찾아야 한다.→ 그래서 팀원 전체가 데이터 수집도 하고 라벨링 작업도 진행하기로 했다.
- Dataset
    - CNR park
    - pklot dataset
    - **[Microsoft COCO 2017 Dataset](https://public.roboflow.com/object-detection/microsoft-coco-subset)**
    

---

## 1차 시도(실외 vs 실내)

### 실내 주차장

- 전체 주차장의 실내, 실외 주차장 빈도를 보았을 때 실내 주차장이 높다.
    
    ![실내주차장1.jpg](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/%EC%8B%A4%EB%82%B4%EC%A3%BC%EC%B0%A8%EC%9E%A51.jpg)
    
    ![실내주차장2.jpg](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/%EC%8B%A4%EB%82%B4%EC%A3%BC%EC%B0%A8%EC%9E%A52.jpg)
    
- 하지만 공개되어있는 실내 주차장 데이터셋을 찾을 수 없었다.
- 모델을 돌릴 수 있을 정도의 양과 질의 데이터셋을 찾을 수 없었다.
- 왜일까? 
→ 비교적 낮고 가까운 곳에서 사진을 찍을 수 밖에 없는 실내 주차장 구조 상, 해당 사진들을 사용할 경우 추후 개인 정보 (얼굴, 자동차 번호 등) 노출로 인한 문제제기가 가능하기에 실내 주차장 학습은 무리가 있다고 판단하였다.
- → 그래서 공개되어있는 실외 주차장 데이터셋을 최대한 활용하기로 결정했다.

### 실외 주차장

- [PKLot 데이터](https://public.roboflow.com/object-detection/pklot)
    
    : Federal University of Parana에서 공개한 오픈 데이터로 자유로운 활용이 가능하고, Yolo에서 필요한 labels의 자료가 있어 잘할 수 있을 것이라 판단했다. 
    
    ![PKLot data](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/pklot_data.png)
    
    PKLot data
    
    ![PKLot Labels](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/pklot1.png)
    
    PKLot Labels
    
- 학습
    - train데이터(8,691장)
    valid데이터(2,483장)
    test데이터(1,243장)
    - 8,691장의 학습( epochs 20 / batches 32 )
        
        ![PKLot 학습 결과](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/pklot_results.png)
        
        PKLot 학습 결과
        
    - mAP 0.5 : 0.991
    mAP 0.95 : 0.867
- 결과
    - PKLot test데이터 결과
        
        [PKLot test 데이터 결과](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/pklot_test.jfif)
        
        PKLot test 데이터 결과
        
    - 기타 데이터 결과
        
        ![PKLot 모델에 다른 test 데이터 결과](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/pklot_test.png)
        
        PKLot 모델에 다른 test 데이터 결과
        
        - 위에 사진은 PKLot 에서 학습한 사진이라 괜찮은 결과를 보이지만 아래 사진의 경우 우려했던 카메라의 각도라는 변수 때문에 detect에 한계가 보인다.

### 1차 시도의 결론 및 피드백

1. 실내 데이터는 개인정보의 문제로 인해 부족하기 때문에 실외 데이터로 진행하자. 
2. 라벨링에 대한 부분도 실제로 확인해보니 주차장의 정확한 범위(지나가는 차와 주차되어 있는 차를 정확히 구분)를 일관되게 설정하는 것이 중요함을 알게 되었다. 
3. PKLot 데이터가 train이 8000장이지만 4000장씩 2개의 카메라만 존재해서 생각보다 빠른 시간(5epoch에서)내에 overfitting에 도달했다. 그에 따라 다른 데이터에 확장성은 많지 않았다.
    
    ![위 사진은 PKLot 학습과 비슷한 주차장, 아래 사진은 상이한 주차장](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/pklot_test.png)
    
    위 사진은 PKLot 학습과 비슷한 주차장, 아래 사진은 상이한 주차장
    
    카메라 각도가 비슷한 사진들은 80%까지 detect 하는 것을 보니 **카메라 각도**가 중요한 feature이지 않을까?                                                                                                       
    

---

## 2차 시도(카메라 각도에 따른 학습)

### 데이터셋

- CNR park
    - 총 9개의 카메라로 한 주차장의 이미지를 수집한 데이터이다.
    - 각 카메라는 다른 각도를 가지고 있기 때문에, 각 카메라 별로 따로 학습을 시켜주어 테스트해보자!
    - 예시
        
        ![cnr_data.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/cnr_data.png)
        
- 데이터 라벨링
    - 1차 시도에서 사용한 PKLot 데이터 라벨링 방식을 바탕으로 일관된 라벨링을 진행하였다.
    - [LabelImg](https://github.com/tzutalin/labelImg)을 (PASCAL VOC format, Yolov5 format 등을 지원)을 이용하였다.
        - 총 약 1,300장의 이미지에 라벨링을 부여함
        - 라벨링 class는 총 두가지: ‘car’, ‘emtpy’
        - (새벽 4시까지 라벨링하고 올려주시는 팀원님들...)
            
            ![KakaoTalk_Snapshot_20220103_201009.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/KakaoTalk_Snapshot_20220103_201009.png)
            
    - 예시)
        
        ![LabelImg 프로그램을 이용한 Yolov5 라벨링 예시](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/%EB%9D%BC%EB%B2%A8%EB%A7%81.jpg)
        
        LabelImg 프로그램을 이용한 Yolov5 라벨링 예시
        

### 학습

- 2번 카메라
    - 2015/11/13 - 2015/11/29 train데이터 (260장)
    2015/12/01 - 2015/12/05 valid데이터(43장)
    2016/01/14 - 2016/01/16 test데이터(43장)
    - 260장의 학습( epochs 50 / batch 30 )
        
        ![2번카메라_results.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/2%EB%B2%88%EC%B9%B4%EB%A9%94%EB%9D%BC_results.png)
        
    - mAP 0.5 : 0.976 
    mAP 0.95 : 0.632
        - mAP(mean average precision)란?
            - Precision : 분류기의 성능평가지표로 사용하는 Precision-Recall 에서의 Precision과 같은 의미이다. 인식기 (object-detector) 가 검출한 정보들 중에서 Ground-Truth 와 일치하는 비율을 의미
            - AP (Average Precision) : Recall value [0.0, 0.1, …, 1.0] 값들에 대응하는 Precision 값들의 Average
            - mAP (mean Average Precision) : 1개의 object당 1개의 AP 값을 구하고, 여러 object-detector 에 대해서 mean 값을 구한 것이 mAP
- 8번 카메라
    - 2015/11/13 - 2015/11/29 train데이터 (371장)
    2015/12/01 - 2015/12/05 valid데이터(38장)
    2016/01/14 - 2016/01/16 test데이터(40장)
    - 371장의 학습( epochs 50 / batch 30 )
        
        ![8번카메라_results.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/8%EB%B2%88%EC%B9%B4%EB%A9%94%EB%9D%BC_results.png)
        
    - mAP 0.5 : 0.986 
    mAP 0.95 : 0.768
- 9번 카메라
    - 2015/11/13 - 2015/11/29 train데이터 (407장)
    2015/12/01 - 2015/12/05 valid데이터(43장)
    2016/01/14 - 2016/01/16 test데이터(40장)
    - 407장의 학습( epochs 50 / batch 30 )
        
        ![9번카메라_results.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/9%EB%B2%88%EC%B9%B4%EB%A9%94%EB%9D%BC_results.png)
        
    - mAP 0.5 : 0.987
    mAP 0.95 : 0.53

### 결과

- 2번 카메라 결과
    
    ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%201.png)
    
- 8번 카메라 결과
    
    ![8번카메라_test.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/8%EB%B2%88%EC%B9%B4%EB%A9%94%EB%9D%BC_test.png)
    
- 9번 카메라 결과
    
    ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%202.png)
    

### 2차 시도의 결론 및 피드백

1. 한 주차장을 잘 학습한다면 해당 주차장의 다른 시간대에서 충분히 좋은 결과를 낼 수 있다.
2. 비슷한 각도라고 판단되는 8번 카메라 모델로도 다른 주차장에서 아쉬운 결과를 보이는데, 차와 빈 자리를 논리적으로 찾는 것이 아니라 라벨링 되어있는 그 부분의 **지형지물**을 학습하는 것으로 보인다. 차량의 방향도 중요하지만 그 주차장 고유의 상황이 더 중요하다.
    - 8번 카메라 모델로 다른 test 결과
    
    ![8번 카메라 모델로 다른 test 데이터 결과](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/8%EB%B2%88%EC%B9%B4%EB%A9%94%EB%9D%BC%EB%A1%9C_park.png)
    
    8번 카메라 모델로 다른 test 데이터 결과
    
3. 그렇다면 데이터가 많이 부족한 상황에서 어떤 기법을 사용하는 것이 좋을까?

---

## 3차 시도(데이터 최적화)

데이터가 부족한 상황, 우린 어떻게 대처할 수 있을까. 

주차장 고유의 상황이 중요하다면, 서로 다른 주차장에서의 데이터는 서로 커버할 수 없을까?

- 이에 시도할 수 있는 방법들
    - data augmentation
        - image rotation, shear, mixup의 기법을 사용한 결과, 같은 데이터셋에서 좋은 성능을 나타냄
        - CNR Park camera9에서 시도할 결과, 더 좋은 성능을 보여줌
            - 예시1) 아래 결과에서 어두울 때, 더 정확하게 주차된 차량을 잡아냄
            - 예시2) 빈자리가 많은 경우에도, 빈자리와 차를 더 높은 정확도로 많이 잡아냄

![예시1) Rotation, shear, mixup 적용](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled.jpeg)

예시1) Rotation, shear, mixup 적용

![예시2) Rotation, shear, mixup 적용](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%201.jpeg)

예시2) Rotation, shear, mixup 적용

![예시1) Rotation, shear, mixup 적용되지 않음](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%202.jpeg)

예시1) Rotation, shear, mixup 적용되지 않음

![예시2) Rotation, shear, mixup 적용되지 않음](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%203.jpeg)

예시2) Rotation, shear, mixup 적용되지 않음

→ 그렇다면 data augmentation 기법을 이용한다면, 다른 주차장(확장성의 문제)에서도 더 좋은 결과값을 얻을 수 있을까?

- 데이터셋(test 200장)
    - parking net(100장)
        - ~~parking net 사진 2장~~
    - parking net(200장)
    - 200장에 대한 [라벨링 작업](https://www.notion.so/43b685385f8447da912f412bc3ba4447) 진행
- 학습
    - ~~결과 표~~
- 결과
    - ~~테스트 결과 사진 good~~
    - ~~비슷한 주차장인 park.mp4 실패~~

### 3차 시도 결과 및 피드백-

- 데이터가 많지 않은 상황에서 image augmentation으로 성능을 향상시킬 수 있었다.
- 특별히 주차장 데이터셋에는 rotataion, shear, exposure adjustment 등이 중요. (@이찬행 학습 후 수정 예정)

---

## 4차 시도(확장성)

### 앙상블

주차장을 학습하는 것이 가장 좋은 방법이지만 많은 자원(시간, 인력)이 필요로 하기 때문에 이를 해결하고 서비스 형태가 되기 위해서 바로 투입이 가능한 형태의 모델이 필요하다고 판단했다. 그래서 주차장의 지형지물이 아닌 car를 학습한 모델을 준비했다.

- COCO 데이터 12,000장 학습한 모델
    - **[Microsoft COCO 2017 Datase](https://public.roboflow.com/object-detection/microsoft-coco-subset)t**
        
        COCO Dataset(121,408장)에서 차가 존재하는 이미지만을 사용해서 12,000장의 이미지로 학습을 진행했다.
        
    - 라벨링 방법
        - 11만장의 데이터를 모두 활용할 필요가 없기 때문에, 
        car이 있는 파일들만 정제해서 사용
            
            ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%203.png)
            
        - car가 **Microsoft COCO 2017 Dataset에서** 18번 class인 것을 
        프로젝트에 맞게 학습시키기 위해 4번 class로 수정
        - 결과적으로 car 12000장, person 10000장으로 축소
        
- 앙상블(COCO+ augmentation COCO)
    - 결과
        
        Yolov5와 비교하는 도표
        
        ![car_detect.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/car_detect.png)
        

### person blur(개인정보보호)

- 현재 cctv를 비롯한 여러 카메라에 관한 이슈가 끊이지 않는데, 그 중에 가장 중요한 이슈는 ‘개인 정보’이다. 사진에서 사람을 분류해서 그 사람을 **blur처리**하는 모델 구현을 통해 개인 정보 문제에 대응하였다.
- 학습
    - COCO 데이터 10,000장의 person 데이터를 학습
        - **[Microsoft COCO 2017 Dataset](https://public.roboflow.com/object-detection/microsoft-coco-subset)**
            
            COCO Dataset(121,408장)에서 사람이 존재하는 이미지만을 사용해서 10,000장의 이미지로 학습을 진행했다.
            
- person blur 결과
    
    ![youtube 동방신기 ‘Mirotic’ 영상 중 일부로 blur 처리된 모습](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/%EB%8F%99%EB%B0%A9%EC%8B%A0%EA%B8%B0blur.png)
    
    youtube 동방신기 ‘Mirotic’ 영상 중 일부로 blur 처리된 모습
    

### Time(정확성)

- 주차장의 사진이 어느 시점에 찍혔는지 알아야 사용자가 정확한 주차 가능 여부를 파악할 수 있기에 사진 위에 detect 시점의 시간 정보를 추가하게 되었다.
    
    ![time.jpg](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/time.jpg)
    

### 4차 시도 결과 및 피드백

- ‘car’만 detect하는 모델과, 각 카메라에 따로 학습한 모델들을 앙상블로 사용했을 때, 효과가 가장 좋았다.
    - ‘car’만 존재하는 모델이 쓰였기 때문에, ‘car’ 클래스는 굉장히 잘 잡을 수 있다. 
    그렇다면 다른 방법으로 전체 empty space를 카운트한 뒤, ‘car’ 객체의 수의 차이를 이용해 주차 가능 여부를 알려줄 수 있을 것이라 판단했다. 
    →  **empty space = 전체 empty space - car의 수**
- 데이터가 많지 않다면, 적절한 data augmentation 기법과 여러 모델로 구성된 앙상블 모델이 확장성을 가질 수 있을 것이다.

---

## 서비스

### 웹사이트

- 실질적인 사용자 경험 개선을 위해서 우리가 찾은 주차 공간을 알리고자 웹사이트를 구현하였다.
- 웹사이트 구조
    
    ![Untitled](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/Untitled%204.png)
    
    - SOCAR ZONE정보와 주차장 사진을 서버와 DB가 connect
    - client가 직관적으로 이해하고 파악하도록 kakao map API를 활용해 지도를 통해 접근
        
        ![카카오맵 api.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/%EC%B9%B4%EC%B9%B4%EC%98%A4%EB%A7%B5_api.png)
        
- 데이터 베이스 종류
    - SOCAR_ZONE
    : 쏘카존 이름, 쏘카존 위도, 쏘카존 경도, 주소, 현재 주차장 빈자리 수, 주차장 만차 수
    - Client
    : 이메일, 비밀번호, 이름
    - File
    : 쏘카존 이름, 주차장 사진
    

---

## 결과물

### 웹사이트

- 주소:
    
    [teamdi.xyz](http://teamdi.xyz/)
    
    - 공식 id / 공식 비밀번호
    abcd@naver.com / 123
    - 웹사이트
    
    ![로그인 페이지](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/login_page.png)
    
    로그인 페이지
    
    ![지도 페이지](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/main_page.png)
    
    지도 페이지
    
    ![클릭시 detect된 사진 페이지](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A9%E1%86%BC%20d19a79ebb48d44fe899872f9bf953bf5/click_page.png)
    
    클릭시 detect된 사진 페이지
    
    - client 사용 방법
    - 데이터 넣는 방법

---

## 예상 질문들

### Q. 몇 장의 데이터면 주차장을 학습할 수 있나요?

A. 현재 150장 사진을 라벨링 할 수 있으면 90% 이상의 정확도로 가능하다고 판단합니다. 

(data augmentation 사용시)

~~150장 활용 / 200장 활용 / 350장 활용~~

### Q. 1,047개의 쏘카존을 어떻게 해결할 수 있나요?

A. 200장 기준 대략 3시간이 걸리는데 최저시급으로 (1047*3시간*최저시급) = 4,000만원 이라고 판단됩니다.

 하지만 앙상블 기법을 통해서 모델들의 앙상블을 통해 차의 개수만 파악할 수 있으면 정확한 주차장 라벨링을 굳이 하지 않아도, 주차장의 ‘주차 가능한 차량 개수’만 입력해도 어느 정도 정보를 제공할 수 있다고 판단됩니다.

---

# 참고

- [https://better-today.tistory.com/3](https://better-today.tistory.com/3)
- 

## 수집

주차장의 이미지 데이터를 수집할 수 있는 대표적인 경로는 cctv와 쏘카 차량에 부착된 블랙박스이다. 하지만 풀고자 하는 문제를 고려해보았을 때 블랙박스 데이터는 실시간으로 주차장의 주차 가능 여부를 파악하지 못하기 때문에 cctv에서 수집할 수 있는 이미지 데이터를 얻는 것이 가장 효과적이다.

하지만 많은 쏘카존에서 접근 가능한 cctv 이미지는 한정적이다. 많은 쏘카존들이 속해있는 주차 건물은 쏘카가 아닌 다른 기업에서 운영되고 있으며, cctv가 녹화한 이미지에는 민감한 정보가 들어있을 수 있기 때문이다. 특히 사람이 나온 이미지가 강력한 예시가 될 수 있는데, 이를 고려하여 사람을 판별하여 blur할 수 있는 모델도 개발하였다.

공개 데이터셋들을 사용하는 모델과 호환될 수 있게, 학습을 원하는 객체를 대상으로 총 x개의 이미지에 대해 라벨링을 진행했다.

## 라벨링

### 라벨링 방법

Objection detection model에 사용할 pretrained model은 yolov5이다. yolov5는 아래와 같은 형식의 txt 파일의 라벨링을 가지고 있어, 이를 위해 ...를 이용하려 라벨링을 작업하였다. 총 x개의 이미지에 대해 person, car, empty space에 대해 building box를 만들었다. 총 작업 소요 시간은 ...이다.dr

---